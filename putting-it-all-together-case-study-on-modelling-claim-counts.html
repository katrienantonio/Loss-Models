<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>4 Putting it all together: case study on modelling claim counts | Loss Models : a collection of computer labs in R</title>
  <meta name="description" content="Tutorials for the course of Loss Models">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="4 Putting it all together: case study on modelling claim counts | Loss Models : a collection of computer labs in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Tutorials for the course of Loss Models" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Putting it all together: case study on modelling claim counts | Loss Models : a collection of computer labs in R" />
  
  <meta name="twitter:description" content="Tutorials for the course of Loss Models" />
  

<meta name="author" content="Katrien Antonio and Jonas Crevecoeur">


<meta name="date" content="2020-09-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="simple-parametric-distributions-for-frequency-and-severity-data.html">
<link rel="next" href="simulation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script>
$(document).ready(function() {

  $chunks = $('.fold');

  $chunks.each(function () {

    // add button to source code chunks
      $(this).prepend("<div class=\"showopt\">Show Solution</div><br style=\"line-height:22px;\"/>");
 
	$child = $(this).children('div');
	$child.each(function(){
		$(this).children('').attr('class', 'folded');
	});
	$(this).children('pre').attr('class', 'folded');
	$(this).children('p').attr('class', 'folded');
   });

  // hide all chunks when document is loaded
  $('.folded').css('display', 'none')

  // function to toggle the visibility
  $('.showopt').click(function() {
    var label = $(this).html();
    if (label.indexOf("Show") >= 0) {
      $(this).html(label.replace("Show", "Hide"));
    } else {
      $(this).html(label.replace("Hide", "Show"));
    }
    	$child = $(this).siblings('div');
	$child.each(function(){
		$(this).children('pre').slideToggle('fast', 'swing');
	});
	$(this).siblings('pre').slideToggle('fast', 'swing');
	$(this).siblings('p').slideToggle('fast', 'swing');
  });
});
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Intro</a></li>
<li class="chapter" data-level="2" data-path="data-exploration.html"><a href="data-exploration.html"><i class="fa fa-check"></i><b>2</b> Data exploration</a><ul>
<li class="chapter" data-level="2.1" data-path="data-exploration.html"><a href="data-exploration.html#importing-data-in-r"><i class="fa fa-check"></i><b>2.1</b> Importing data in R</a><ul>
<li class="chapter" data-level="2.1.1" data-path="data-exploration.html"><a href="data-exploration.html#determining-the-file-path"><i class="fa fa-check"></i><b>2.1.1</b> Determining the file path</a></li>
<li class="chapter" data-level="2.1.2" data-path="data-exploration.html"><a href="data-exploration.html#import-a-.txt-file"><i class="fa fa-check"></i><b>2.1.2</b> Import a .txt file</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="data-exploration.html"><a href="data-exploration.html#data-exploration-1"><i class="fa fa-check"></i><b>2.2</b> Data exploration</a><ul>
<li class="chapter" data-level="2.2.1" data-path="data-exploration.html"><a href="data-exploration.html#variable-types"><i class="fa fa-check"></i><b>2.2.1</b> variable types</a></li>
<li class="chapter" data-level="2.2.2" data-path="data-exploration.html"><a href="data-exploration.html#factor-variables"><i class="fa fa-check"></i><b>2.2.2</b> Factor variables</a></li>
<li class="chapter" data-level="2.2.3" data-path="data-exploration.html"><a href="data-exploration.html#numeric-variables"><i class="fa fa-check"></i><b>2.2.3</b> Numeric variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html"><i class="fa fa-check"></i><b>3</b> Simple, parametric distributions for frequency and severity data</a><ul>
<li class="chapter" data-level="3.1" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#the-exponential-distribution"><i class="fa fa-check"></i><b>3.1</b> The exponential distribution</a><ul>
<li class="chapter" data-level="3.1.1" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#simulating-data"><i class="fa fa-check"></i><b>3.1.1</b> Simulating data</a></li>
<li class="chapter" data-level="3.1.2" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#exploratory-analysis"><i class="fa fa-check"></i><b>3.1.2</b> Exploratory analysis</a></li>
<li class="chapter" data-level="3.1.3" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#data-visualization-with-ggplot"><i class="fa fa-check"></i><b>3.1.3</b> Data visualization with ggplot</a></li>
<li class="chapter" data-level="3.1.4" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#maximum-likelihood-estimation-mle"><i class="fa fa-check"></i><b>3.1.4</b> Maximum Likelihood Estimation (MLE)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#discrete-distributions"><i class="fa fa-check"></i><b>3.2</b> Discrete distributions</a><ul>
<li class="chapter" data-level="3.2.1" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#simulating-the-data"><i class="fa fa-check"></i><b>3.2.1</b> Simulating the data</a></li>
<li class="chapter" data-level="3.2.2" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#exploratory-analysis-1"><i class="fa fa-check"></i><b>3.2.2</b> Exploratory analysis</a></li>
<li class="chapter" data-level="3.2.3" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#maximum-likelihood-estimation-mle-1"><i class="fa fa-check"></i><b>3.2.3</b> Maximum Likelihood Estimation (MLE)</a></li>
<li class="chapter" data-level="3.2.4" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#comparing-fitted-models"><i class="fa fa-check"></i><b>3.2.4</b> Comparing fitted models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html"><i class="fa fa-check"></i><b>4</b> Putting it all together: case study on modelling claim counts</a><ul>
<li class="chapter" data-level="4.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#read-in-data"><i class="fa fa-check"></i><b>4.1</b> Read in data</a><ul>
<li class="chapter" data-level="4.1.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#determining-the-file-path-1"><i class="fa fa-check"></i><b>4.1.1</b> Determining the file path</a></li>
<li class="chapter" data-level="4.1.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#importing-a-.txt-file"><i class="fa fa-check"></i><b>4.1.2</b> Importing a .txt file</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#exploratory-analysis-2"><i class="fa fa-check"></i><b>4.2</b> Exploratory analysis</a><ul>
<li class="chapter" data-level="4.2.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#summary-statistics-disregarding-exposure"><i class="fa fa-check"></i><b>4.2.1</b> Summary statistics disregarding exposure</a></li>
<li class="chapter" data-level="4.2.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#summary-statistics-taking-into-account-exposure"><i class="fa fa-check"></i><b>4.2.2</b> Summary statistics taking into account exposure</a></li>
<li class="chapter" data-level="4.2.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#empirical-probability-distribution"><i class="fa fa-check"></i><b>4.2.3</b> Empirical probability distribution</a></li>
<li class="chapter" data-level="4.2.4" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#the-a-b-0-class-of-distributions"><i class="fa fa-check"></i><b>4.2.4</b> The (a, b, 0) class of distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#fitting-count-distributions"><i class="fa fa-check"></i><b>4.3</b> Fitting count distributions</a><ul>
<li class="chapter" data-level="4.3.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#poisson"><i class="fa fa-check"></i><b>4.3.1</b> Poisson</a></li>
<li class="chapter" data-level="4.3.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#negative-binomial-1"><i class="fa fa-check"></i><b>4.3.2</b> Negative binomial</a></li>
<li class="chapter" data-level="4.3.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#modified-poisson-distributions"><i class="fa fa-check"></i><b>4.3.3</b> Modified Poisson distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#aic-1"><i class="fa fa-check"></i><b>4.4</b> AIC</a></li>
<li class="chapter" data-level="4.5" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#replicating-data-sets"><i class="fa fa-check"></i><b>4.5</b> Replicating data sets</a><ul>
<li class="chapter" data-level="4.5.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#poisson-1"><i class="fa fa-check"></i><b>4.5.1</b> Poisson</a></li>
<li class="chapter" data-level="4.5.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#nb"><i class="fa fa-check"></i><b>4.5.2</b> NB</a></li>
<li class="chapter" data-level="4.5.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#zip"><i class="fa fa-check"></i><b>4.5.3</b> ZIP</a></li>
<li class="chapter" data-level="4.5.4" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#hurdle-poisson-1"><i class="fa fa-check"></i><b>4.5.4</b> Hurdle Poisson</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#mean-and-variance-of-the-estimated-zip-nb-hurdle-poisson"><i class="fa fa-check"></i><b>4.6</b> Mean and variance of the estimated ZIP, NB, Hurdle Poisson</a><ul>
<li class="chapter" data-level="4.6.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#poisson-2"><i class="fa fa-check"></i><b>4.6.1</b> Poisson</a></li>
<li class="chapter" data-level="4.6.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#nb-1"><i class="fa fa-check"></i><b>4.6.2</b> NB</a></li>
<li class="chapter" data-level="4.6.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#zip-1"><i class="fa fa-check"></i><b>4.6.3</b> ZIP</a></li>
<li class="chapter" data-level="4.6.4" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#hurdle-poisson-2"><i class="fa fa-check"></i><b>4.6.4</b> Hurdle Poisson</a></li>
<li class="chapter" data-level="4.6.5" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#comparison-with-empirical-mean-and-variance"><i class="fa fa-check"></i><b>4.6.5</b> Comparison with empirical mean and variance</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#conclusion"><i class="fa fa-check"></i><b>4.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>5</b> Simulation</a><ul>
<li class="chapter" data-level="5.1" data-path="simulation.html"><a href="simulation.html#severity"><i class="fa fa-check"></i><b>5.1</b> Severity</a><ul>
<li class="chapter" data-level="5.1.1" data-path="simulation.html"><a href="simulation.html#probability-integral-transform"><i class="fa fa-check"></i><b>5.1.1</b> Probability integral transform</a></li>
<li class="chapter" data-level="5.1.2" data-path="simulation.html"><a href="simulation.html#visualization"><i class="fa fa-check"></i><b>5.1.2</b> Visualization</a></li>
<li class="chapter" data-level="5.1.3" data-path="simulation.html"><a href="simulation.html#expected-loss-with-a-deductible"><i class="fa fa-check"></i><b>5.1.3</b> Expected loss with a deductible</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="simulation.html"><a href="simulation.html#aggregate-loss"><i class="fa fa-check"></i><b>5.2</b> Aggregate loss</a></li>
<li class="chapter" data-level="5.3" data-path="simulation.html"><a href="simulation.html#simulating-future-life-times-of-newborns"><i class="fa fa-check"></i><b>5.3</b> Simulating future life times of newborns</a><ul>
<li class="chapter" data-level="5.3.1" data-path="simulation.html"><a href="simulation.html#importing-the-data"><i class="fa fa-check"></i><b>5.3.1</b> Importing the data</a></li>
<li class="chapter" data-level="5.3.2" data-path="simulation.html"><a href="simulation.html#simulate-the-whole-life-time"><i class="fa fa-check"></i><b>5.3.2</b> Simulate the whole life time</a></li>
<li class="chapter" data-level="5.3.3" data-path="simulation.html"><a href="simulation.html#simulate-the-future-lifetime"><i class="fa fa-check"></i><b>5.3.3</b> Simulate the future lifetime</a></li>
<li class="chapter" data-level="5.3.4" data-path="simulation.html"><a href="simulation.html#visualize-the-data"><i class="fa fa-check"></i><b>5.3.4</b> Visualize the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="r-implementation-of-the-assignments-2019-2020.html"><a href="r-implementation-of-the-assignments-2019-2020.html"><i class="fa fa-check"></i><b>6</b> R implementation of the assignments 2019-2020</a><ul>
<li class="chapter" data-level="6.1" data-path="r-implementation-of-the-assignments-2019-2020.html"><a href="r-implementation-of-the-assignments-2019-2020.html#assignment-1"><i class="fa fa-check"></i><b>6.1</b> Assignment 1</a><ul>
<li class="chapter" data-level="6.1.1" data-path="r-implementation-of-the-assignments-2019-2020.html"><a href="r-implementation-of-the-assignments-2019-2020.html#exercise-1"><i class="fa fa-check"></i><b>6.1.1</b> Exercise 1</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="r-implementation-of-the-assignments-2019-2020.html"><a href="r-implementation-of-the-assignments-2019-2020.html#assignment-2"><i class="fa fa-check"></i><b>6.2</b> Assignment 2</a><ul>
<li class="chapter" data-level="6.2.1" data-path="r-implementation-of-the-assignments-2019-2020.html"><a href="r-implementation-of-the-assignments-2019-2020.html#exercise-2"><i class="fa fa-check"></i><b>6.2.1</b> Exercise 2</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Models : a collection of computer labs in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="putting-it-all-together-case-study-on-modelling-claim-counts" class="section level1">
<h1><span class="header-section-number">4</span> Putting it all together: case study on modelling claim counts</h1>
<p>In this tutorial you will import a data set with the number of claims registered on a group of policyholders during one year. You will look for a suitable discrete distribution to model this data set. Hereto you will fit the Poisson, the Negative Binomial, the Zero-Inflated and the Hurdle Poisson to the data, while estimating the parameters used by these distributions with Maximum Likelihood Estimation. As a final step, you will compare the different model fits and select the best fitting parametric distribution.</p>
<div id="read-in-data" class="section level2">
<h2><span class="header-section-number">4.1</span> Read in data</h2>
<p>Importing data is often the first step in any analysis. In this tutorial the data is stored in the file <code>NonFleetCo507Final.txt</code>, which is located in a local subdirectory <code>data</code>. Check out chapter 4 of <a href="https://katrienantonio.github.io/intro_R_book_Oct_2018/started-with-data.html#importing-data">Data science in insurance: an R intro</a> for a detailed overview of the R methods for importing data.</p>
<div id="determining-the-file-path-1" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Determining the file path</h3>
<p>Before we can import the data, we should first determine the exact file path where the data are located. R offers several methods for this task.</p>
<ol style="list-style-type: decimal">
<li><code>file.choose()</code></li>
</ol>
<p><code>file.choose()</code> opens an interactive prompt, which allows you to manually select the location of the file. Once selected R prints the aboslute path to the file in the console.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">file.choose</span>()</code></pre></div>
<pre><code>&quot;C:\Users\u0110176\Dropbox\Verzekeringen niet-leven\Bookdown\data\NonFleetCo507Final.txt&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Store the path in a variable for later use.</span>
path &lt;-<span class="st"> &quot;C:</span><span class="ch">\\</span><span class="st">Users</span><span class="ch">\\</span><span class="st">u0110176</span><span class="ch">\\</span><span class="st">Dropbox</span><span class="ch">\\</span><span class="st">Verzekeringen niet-leven</span><span class="ch">\\</span><span class="st">Bookdown</span><span class="ch">\\</span><span class="st">data</span><span class="ch">\\</span><span class="st">NonFleetCo507Final.txt&quot;</span></code></pre></div>
<ol start="2" style="list-style-type: decimal">
<li><code>setwd(&lt;path&gt;)</code></li>
</ol>
<p><code>setwd(&lt;path&gt;)</code> specifies the working directory of the current R session to <code>&lt;path&gt;</code>. Once set all files in the working directory can be referenced by relative paths.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># This is the map containing all files for the tutorial</span>
<span class="kw">setwd</span>(<span class="st">&quot;C:</span><span class="ch">\\</span><span class="st">Users</span><span class="ch">\\</span><span class="st">u0110176</span><span class="ch">\\</span><span class="st">Dropbox</span><span class="ch">\\</span><span class="st">Verzekeringen niet-leven</span><span class="ch">\\</span><span class="st">Bookdown</span><span class="ch">\\</span><span class="st">&quot;</span>)

<span class="co"># This is a relative path from the working directory to the file we want to import</span>
path &lt;-<span class="st"> &quot;data</span><span class="ch">\\</span><span class="st">NonFleetCo507Final.txt&quot;</span></code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li>Additional methods for <code>RStudio</code></li>
</ol>
<p><code>RStudio</code> offers two additional methods for setting the working directory to the location of the current R file.</p>
<p>Method 1: In the menu click Session -&gt; Set Working Directory -&gt; To Source File Location.</p>
<p>Method 2: Run the following code in the R console</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dir &lt;-<span class="st"> </span><span class="kw">dirname</span>(rstudioapi<span class="op">::</span><span class="kw">getActiveDocumentContext</span>()<span class="op">$</span>path)
<span class="kw">setwd</span>(dir)

path &lt;-<span class="st"> &quot;data</span><span class="ch">\\</span><span class="st">NonFleetCo507Final.txt&quot;</span></code></pre></div>
<p>The advantage of these methods is that the working directory is automatically updated when the file is moved.</p>
</div>
<div id="importing-a-.txt-file" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Importing a .txt file</h3>
<p>After obtaining the file path, we read in the <code>txt</code> file using <code>read.table</code>. We specify the following options:</p>
<ol style="list-style-type: decimal">
<li><code>header = TRUE</code>: The first row of the file contains the variable names.</li>
<li><code>sep = \t</code>: A tab splits the records in the text file.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NonFleet &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="dt">file =</span> path, <span class="dt">header =</span> <span class="ot">TRUE</span>, <span class="dt">sep =</span> <span class="st">&#39;</span><span class="ch">\t</span><span class="st">&#39;</span>)</code></pre></div>
<p>The data is now imported in the data.frame <code>NonFleet</code>. <code>head(&lt;data.frame&gt;)</code> prints the first records of a data.frame. This is a good first check to see whether the data was imported correctly.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Show the first records of the imported data set</span>
<span class="kw">head</span>(NonFleet)</code></pre></div>
<pre><code>  AgeInsured SexInsured Experience TLength Clm_Count VAge PrivateCar NCD_0
1         32          M         11  0.4654         0   10          1     0
2         26          M          5  0.8077         0   13          1     1
3         32          M          5  0.3997         0    0          1     0
4         32          M          5  0.5832         0    1          1     0
5         41          M         14  0.7748         0    9          1     0
6         28          F          3  0.4928         0    0          1     1
  Cover_C VehCapCubic VehCapTonn
1       1        1797          0
2       0        1590          0
3       1        1997          0
4       1        1997          0
5       0        1597          0
6       1        1587          0</code></pre>
<p>Everything looks good. In this tutorial we focus on the variables:</p>
<ol style="list-style-type: decimal">
<li><code>Clm_Count</code>: Number of claims for the policyholder;</li>
<li><code>TLength</code>: Fraction of the year that the policyholder was insured. In insurance this is often called the exposure.</li>
</ol>
<p>We create separate variables in R to store these covariates</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Clm_Count &lt;-<span class="st"> </span>NonFleet<span class="op">$</span>Clm_Count;
TLength &lt;-<span class="st"> </span>NonFleet<span class="op">$</span>TLength;</code></pre></div>
</div>
</div>
<div id="exploratory-analysis-2" class="section level2">
<h2><span class="header-section-number">4.2</span> Exploratory analysis</h2>
<p>We now explore the available data and analyze the number of claim counts per insured.</p>
<div id="summary-statistics-disregarding-exposure" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Summary statistics disregarding exposure</h3>
<p>We start our analysis by computing the mean and variance of the number of observed claims. If we denote by <span class="math inline">\(n_i\)</span> the number of claims observed for policyholder <span class="math inline">\(i\)</span>, we can compute the mean and variance as</p>
<p><span class="math display">\[ \mu = E(X) = \frac{1}{m} \cdot \sum_{i=1}^m n_i\]</span></p>
<p>and</p>
<p><span class="math display">\[ \sigma^2 = E((X - \mu)^2) = \frac{1}{m} \cdot \sum_{i=1}^m (n_i - \mu)^2. \]</span></p>
<p>In these formulas <span class="math inline">\(m\)</span> denotes the number of observations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">length</span>(Clm_Count)

mu &lt;-<span class="st"> </span><span class="kw">sum</span>(Clm_Count) <span class="op">/</span><span class="st"> </span>m
var &lt;-<span class="st"> </span><span class="kw">sum</span>((Clm_Count <span class="op">-</span><span class="st"> </span>mu)<span class="op">^</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>m

<span class="kw">c</span>(<span class="dt">mean =</span> mu,
  <span class="dt">variance =</span> var)</code></pre></div>
<pre><code>    mean variance 
 0.09848  0.10925 </code></pre>
</div>
<div id="summary-statistics-taking-into-account-exposure" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Summary statistics taking into account exposure</h3>
<p>The previous calculation of the mean and variance does not consider the difference in exposure between policyholders. However, it is important to take exposure into account. Let <span class="math inline">\(d_i\)</span> be the exposure for policyholder <span class="math inline">\(i\)</span>, then we calculate the mean as</p>
<p><span class="math display">\[ \mu_{\text{exp}} = \sum_{i=1}^m  \frac{d_i}{\sum_{i=1}^m d_i} \frac{n_i}{d_i} =   \frac{\sum_{i=1}^m n_i}{\sum_{i=1}^m d_i}\]</span> and the variance as <span class="math display">\[ \sigma^2_{\text{exp}}=\frac{\sum_{i=1}^m(n_i-\mu_{exp} \cdot d_i)^2}{\sum_{i=1}^m d_i} . \]</span> For more intuition behind these estimators, check out the <a href="http://freakonometrics.hypotheses.org/2732">blog of Arthur Charpentier</a> and Section 15.6.6 from Klugman et al..</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu &lt;-<span class="st"> </span><span class="kw">sum</span>(Clm_Count) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(TLength); 
var &lt;-<span class="st"> </span><span class="kw">sum</span>((Clm_Count<span class="op">-</span>mu<span class="op">*</span>TLength)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="kw">sum</span>(TLength) 

<span class="kw">c</span>(<span class="dt">mean =</span> mu,
  <span class="dt">variance =</span> var)</code></pre></div>
<pre><code>    mean variance 
  0.1546   0.1675 </code></pre>
<p>This is the expected number of accidents for a policyholder who is insurerd throughout the whole year, i.e. <span class="math inline">\(d_i = 1\)</span>.</p>
</div>
<div id="empirical-probability-distribution" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Empirical probability distribution</h3>
<p><code>table</code> allows us to easily construct a contingency table of the counts.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(Clm_Count)</code></pre></div>
<pre><code>Clm_Count
     0      1      2      3      4      5 
145683  12910   1234    107     12      1 </code></pre>
<p>R can plot this table</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">table</span>(Clm_Count))</code></pre></div>
<p><img src="_main_files/figure-html/claimCounts_probability_distribution-1.png" width="576" style="display: block; margin: auto;" /></p>
<p><code>prop.table</code> can be used to obtain the empirical probability distribution</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">prop.table</span>(<span class="kw">table</span>(Clm_Count))</code></pre></div>
<pre><code>Clm_Count
        0         1         2         3         4         5 
9.108e-01 8.071e-02 7.715e-03 6.690e-04 7.502e-05 6.252e-06 </code></pre>
<p>We can create a better barplot using ggplot</p>
<ul>
<li><code>ggplot()</code>: starts the construction of a ggplot figure;</li>
<li><code>geom_bar(...)</code>: creates a bar plot;</li>
<li><code>aes(&lt;var&gt;)</code>: specifies the variables used to create the plot.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Run the following line of code when the package ggplot2 is not yet installed.</span>
<span class="co"># install.package(ggplot2)</span>

<span class="co"># Load the package ggplot2</span>
<span class="kw">library</span>(ggplot2)

<span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(Clm_Count))</code></pre></div>
<p><img src="_main_files/figure-html/claimCounts_barplot_count-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>To specify your own theme, you define some visualisation parameters and colors that will be used in your ggplot calls.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">col &lt;-<span class="st"> &quot;#003366&quot;</span>
fill &lt;-<span class="st"> &quot;#99CCFF&quot;</span></code></pre></div>
<p>Instead of manually changing all details of the plot, ggplot also offers some general layout schemes. In this tutorial we use the black and white theme <code>theme_bw()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(Clm_Count), <span class="dt">col =</span> col, <span class="dt">fill =</span> fill) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="_main_files/figure-html/claimCounts_barplot_count_improved-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The weight argument in <code>aes</code> allows you to weight the number of policyholders who file 0 claims, 1 claim and so on by exposure instead of simply counting the number of policyholders.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(Clm_Count, <span class="dt">weight =</span> TLength), <span class="dt">col =</span> col, <span class="dt">fill =</span> fill) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="_main_files/figure-html/claimCounts_barplot_count_weighted-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>You should check ggplot2 barplot to learn more. <a href="https://ggplot2.tidyverse.org/reference/geom_bar.html" class="uri">https://ggplot2.tidyverse.org/reference/geom_bar.html</a></p>
</div>
<div id="the-a-b-0-class-of-distributions" class="section level3">
<h3><span class="header-section-number">4.2.4</span> The (a, b, 0) class of distributions</h3>
<p>We test whether the data could come from a distribution in the (a, b, 0) class of distributions. Distributions in this family satisfy <span class="math display">\[ \frac{k \cdot p_k}{p_{k-1}} = a \cdot k+ b, \quad k = 1,\ldots,\infty \]</span></p>
<ul>
<li><code>geom_point</code>: adds a scatterplot to ggplot. Two variables have to be specified in <code>aes</code>.</li>
<li><code>xlab</code>: specifies the name of the label on the x-axis.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># We first determine the empirical probabilities p_k</span>
p &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(<span class="kw">table</span>(Clm_Count) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(Clm_Count))

<span class="co"># We calculate the left hand side (lhs) of the relation above</span>
lhs &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">length</span>(p)<span class="op">-</span><span class="dv">1</span>)) <span class="op">*</span><span class="st"> </span>p[<span class="dv">2</span><span class="op">:</span><span class="kw">length</span>(p)] <span class="op">/</span><span class="st"> </span>p[<span class="dv">1</span><span class="op">:</span>(<span class="kw">length</span>(p)<span class="op">-</span><span class="dv">1</span>)]

<span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span>(<span class="kw">length</span>(p)<span class="op">-</span><span class="dv">1</span>), <span class="dt">y =</span> lhs)) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;k&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&#39;lhs&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<p><img src="_main_files/figure-html/claimCounts_scatterplot_ab-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>You should check ggplot2 geom_point to learn more. <a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="uri">https://ggplot2.tidyverse.org/reference/geom_point.html</a></p>
<p>The observations <span class="math inline">\((k, \frac{k \cdot p_k}{p_{k-1}})\)</span> seem to be on a straight line with positive intercept. This indicates that the Negative Binomial distribution might be a good fit for the data.</p>
</div>
</div>
<div id="fitting-count-distributions" class="section level2">
<h2><span class="header-section-number">4.3</span> Fitting count distributions</h2>
<p>We fit several count distributions to the observed claim count data:</p>
<ul>
<li>Poisson</li>
<li>Negative binomial (NB)</li>
<li>Modified Poisson distributions</li>
</ul>
<p>We do not consider the explanatory variables, but take the exposure into account. We fit these distributions using Maximum Likelihood Estimation (MLE).</p>
<div id="poisson" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Poisson</h3>
<p>For a Poisson distribution with intensity <span class="math inline">\(\lambda\)</span> the probability of observing <span class="math inline">\(k\)</span> events is given by</p>
<p><span class="math display">\[ P(N = k) = \exp(-\lambda) \frac{\lambda^k}{k!}.\]</span></p>
<p>The expected value of the poisson distribution is</p>
<p><span class="math display">\[ E(N) = \lambda. \]</span></p>
<p>Not all policyholders are insured throughout the whole year (<span class="math inline">\(d_i = 1\)</span>) and obviously policyholders who are only at risk for a small fraction of the year are less likely to experience a claim. We assume that the claim intensity is proportional to the exposure, i.e.</p>
<p><span class="math display">\[ N_i \sim \text{POI}(d_i \cdot \lambda),\]</span></p>
<p>such that the expected value scales with exposure</p>
<p><span class="math display">\[ E(N_i) = d_i \cdot \lambda.\]</span></p>
<p>We then interpret <span class="math inline">\(\lambda\)</span> as the expected number of claims for a policyholder who was insured throughout the whole year.</p>
<p>Let <span class="math inline">\(m\)</span> be the number of observations and <span class="math inline">\(n_i\)</span> be the observed number of claims for policyholder <span class="math inline">\(i\)</span>, then the likelihood is given by</p>
<p><span class="math display">\[ \mathcal{L}(\lambda) = \prod_{i=1}^m P(N_i = n_i) = \prod_{i=1}^m \exp(-\lambda \cdot d_i) \cdot \frac{(\lambda \cdot d_i)^{n_i}}{n_i!}\]</span></p>
<p>and the loglikelihood is</p>
<p><span class="math display">\[ \ell(\lambda) = \sum_{i=1}^m -\lambda \cdot d_i + n_i \cdot \log(\lambda \cdot d_i) - \log(n_i !).\]</span></p>
<p>We want to maximize this loglikelihood with respect to <span class="math inline">\(\lambda\)</span>. We define a function <code>poisson.loglikelihood</code> which returns the loglikelihood as a function of <span class="math inline">\(\lambda\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">poisson.loglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(lambda)
{
  loglikelihood &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>TLength <span class="op">+</span><span class="st"> </span>Clm_Count <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(lambda <span class="op">*</span><span class="st"> </span>TLength) <span class="op">-</span><span class="st"> </span><span class="kw">lfactorial</span>(Clm_Count))
  
  <span class="kw">return</span>(loglikelihood)
}</code></pre></div>
<p>Unfortunately it is not possible to maximize this function directly in R. We make two small adjustments</p>
<ol style="list-style-type: decimal">
<li><p>We will use the <code>nlm</code> (non-linear minimizer) function in <code>R</code> for finding the maximum likelihood parameter <span class="math inline">\(\hat{\lambda}\)</span>. Because, <code>nlm</code> is used to minimize a function, we change the routine to return the negative loglikelihood (<span class="math inline">\(-\ell(\lambda)\)</span>). Minmizing the negative loglikelihood is equivalent to maximizing the loglikelihood.</p></li>
<li><p>The parameter <span class="math inline">\(\lambda\)</span> is restricted to positive values. The built-in algorithms in R look for parameters in the unrestricted domain <span class="math inline">\((-\infty, \infty)\)</span>. We reparametrize the likelihood and optimize for <span class="math inline">\(\beta = \log(\lambda)\)</span>, which can take values in <span class="math inline">\((-\infty, \infty)\)</span>.</p></li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">poisson.negLoglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(beta)
{
  lambda =<span class="st"> </span><span class="kw">exp</span>(beta)
  
  <span class="kw">return</span>(<span class="op">-</span><span class="kw">poisson.loglikelihood</span>(lambda))
}</code></pre></div>
<p>We use the non-linear minimization function <code>nlm</code> to carry out the minimization. This routine requires a starting value for <span class="math inline">\(\beta\)</span>, which is here simply set to 0. The function returns a list containing the following output (check the help page ?nlm for more details):</p>
<ul>
<li>minimum: the value of the estimated minimum of f.</li>
<li>estimate: the point at which the minimum value of f is obtained.</li>
<li>gradient: the gradient (first derivative) at the estimated minimum of f. The gradient should be close to zero.</li>
<li>hessian: the hessian (second derivative) at the estimated minimum of f. The hessian is used to determine confidence bounds for the parameters fitted through maximum likelihood.</li>
<li>code: an integer indicating why the optimization process terminated. When <code>code</code> equals 1 or 2, the algorithm converged and the current estimate is probably the solution. When <code>code</code> equals 3, 4 or 5 the algorithm has not converged. For more details see the help page of nlm (?nlm).</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">nlm</span>(poisson.negLoglikelihood, <span class="dv">0</span>, <span class="dt">hessian =</span> <span class="ot">TRUE</span>)</code></pre></div>
<pre><code>Warning in nlm(poisson.negLoglikelihood, 0, hessian = TRUE): NA/Inf replaced by
maximum positive value</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit</code></pre></div>
<pre><code>$minimum
[1] 50834

$estimate
[1] -1.867

$gradient
[1] 0.0003585

$hessian
      [,1]
[1,] 15754

$code
[1] 1

$iterations
[1] 7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Store the fitted lambda value</span>
poisson.lambda &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate)

<span class="co"># Store the minimal value found for the loglikelihood</span>
poisson.loglik &lt;-<span class="st"> </span><span class="kw">poisson.loglikelihood</span>(poisson.lambda)</code></pre></div>
<p>The estmiate for <span class="math inline">\(\lambda\)</span> is identical to the expected value <span class="math inline">\(\mu_{\text{exp}}\)</span> we calculated earlier by taking exposure into account.</p>
<p>When we fit the data with maximum likelihood we obtain a point estimate <span class="math inline">\(\hat{\lambda}\)</span> for the intensity of the Poisson process However, sometimes (e.g.Â when doing hypothesis testing) we also need a confidence interval for the actual parameter <span class="math inline">\(\lambda\)</span>. Under MLE we know that the actual parameters of the distribution are assymptoticaly distributed as (see Chapter 13 on Variance and interval estimation)</p>
<p><span class="math display">\[ \lambda \sim \mathcal{N}(\hat{\lambda}, \mathcal{I}^{-1}),\]</span> where <span class="math inline">\(\mathcal{I}\)</span> denotes the Fisher information matrix. You calculate this matrix as the negative of the Hessian, the matrix with the second order derivatives of the log-likelihood, evaluated in <span class="math inline">\(\hat{\beta}\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The standard error of the parameter estimate for beta is</span>
beta.se =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">solve</span>(fit<span class="op">$</span>hessian))</code></pre></div>
<p>You can now use the delta method (see Section 13.3 in the book) to construct a confidence interval for the unknown <span class="math inline">\(\lambda\)</span>. The MLE for <span class="math inline">\(\lambda\)</span> is obtained from the transformation <span class="math inline">\(\hat{\lambda}=\exp \hat{\beta}\)</span>. The corresponding se is calculated as <span class="math inline">\(se_{\hat{\lambda}} = (\exp \hat{\beta})^2 \cdot \text{se}_{\hat{\beta}}\)</span>.</p>
<p>We can use this normal approximation to calculate a <span class="math inline">\(95\%\)</span> confidence interval for the actual parameter <span class="math inline">\(\lambda\)</span> as</p>
<p><span class="math display">\[ [\lambda - \Phi^{-1}(0.975) \cdot \sigma_{\lambda}, \lambda + \Phi^{-1}(0.975) \cdot \sigma_{\lambda}] \]</span>,</p>
<p>where <span class="math inline">\(\Phi\)</span> is the CDF of the standard normal distributon and <span class="math inline">\(\sigma_{\lambda}\)</span> is the standard error of the <span class="math inline">\(\lambda\)</span> parameter.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The standard error of the parameter estimate for lambda is</span>
poisson.se =<span class="st"> </span>poisson.lambda<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>beta.se;

<span class="co"># The 95% confidence interval for lambda is</span>
<span class="kw">c</span>(poisson.lambda <span class="op">-</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>poisson.se, poisson.lambda <span class="op">+</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>poisson.se)</code></pre></div>
<pre><code>[1] 0.1542 0.1549</code></pre>
</div>
<div id="negative-binomial-1" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Negative binomial</h3>
<p>The probability function for the negative binomial distribution is given by</p>
<p><span class="math display">\[Pr(N=k) = \frac{\Gamma(a+k)}{\Gamma(a) k!}\left(\frac{\mu}{\mu+a}\right)^{k}\left(\frac{a}{\mu+a}\right)^{a}.\]</span></p>
<p>We take exposure into account and model <span class="math inline">\(\mu_i = d_i \cdot \mu\)</span>, where <span class="math inline">\(\mu\)</span> is the expected number of claims for a policyholder who is insured for a full year. The likelihood now contains two parameters <span class="math inline">\(a\)</span> and <span class="math inline">\(\mu\)</span> which we have to optimize simultaneously. We define the negative loglikelihood</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NB.negativeLoglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(beta)
{
  mu &lt;-<span class="st"> </span><span class="kw">exp</span>(beta[<span class="dv">1</span>])
  a &lt;-<span class="st"> </span><span class="kw">exp</span>(beta[<span class="dv">2</span>])
  
  loglikelihood &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">lgamma</span>(a <span class="op">+</span><span class="st"> </span>Clm_Count) <span class="op">-</span><span class="st"> </span><span class="kw">lgamma</span>(a) <span class="op">-</span><span class="st"> </span><span class="kw">lfactorial</span>(Clm_Count) <span class="op">+</span><span class="st"> </span>Clm_Count <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(mu<span class="op">*</span>TLength<span class="op">/</span>(mu<span class="op">*</span>TLength <span class="op">+</span><span class="st"> </span>a)) <span class="op">+</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(a <span class="op">/</span><span class="st"> </span>(mu <span class="op">*</span><span class="st"> </span>TLength <span class="op">+</span><span class="st"> </span>a)))
  
  <span class="kw">return</span>(<span class="op">-</span>loglikelihood)
}</code></pre></div>
<p>In this case itâs more important to supply good starting values for the convergence speed of the algorithm. For the Negative Binomial distribution <span class="math display">\[ E(X) = \mu \quad \text{and} \quad Var(X) = \mu + \frac{1}{a} \cdot \mu^2.\]</span> We match the first two moments and set</p>
<p><span class="math display">\[ \mu = E(X) \quad \text{and} \quad a = \frac{\mu^2}{Var(X) - \mu}.\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mu.initial &lt;-<span class="st"> </span>mu
a.initial &lt;-<span class="st"> </span>mu<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(var <span class="op">-</span><span class="st"> </span>mu) 

fit &lt;-<span class="st"> </span><span class="kw">nlm</span>(NB.negativeLoglikelihood, <span class="kw">log</span>(<span class="kw">c</span>(mu.initial, a.initial)),<span class="dt">hessian=</span><span class="ot">TRUE</span>)

<span class="co"># Store the fitted values</span>
nb.mu &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">1</span>])
nb.a &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">2</span>])

<span class="co"># Store the minimal value found for the loglikelihood</span>
nb.loglik &lt;-<span class="st"> </span><span class="op">-</span>fit<span class="op">$</span>minimum</code></pre></div>
</div>
<div id="modified-poisson-distributions" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Modified Poisson distributions</h3>
<p>We consider two popular modifications of the Poisosn distribution, namely the Zero Inflated Poisson (ZIP) distribution and the Hurdle Poisson distribution.</p>
<div id="zero-inflated-poisson-zip" class="section level4">
<h4><span class="header-section-number">4.3.3.1</span> Zero Inflated Poisson (ZIP)</h4>
<p>The ZIP distribution is a Poisson distribution where the probability of having zero claims is increased by <span class="math inline">\(p\)</span>.</p>
<p><span class="math display">\[ P(N = k) = 
\begin{cases} 
  p + (1-p) \cdot P(\tilde{N} = 0) &amp; k = 0 \\
  (1-p) \cdot P(\tilde{N} = k) &amp; k &gt; 0
\end{cases},\]</span></p>
<p>where <span class="math inline">\(\tilde{N}\)</span> follows a Poisson distribution. The ZIP distribution is the mixture of a degnerate distribution in zero with weight <span class="math inline">\(p\)</span> and a Poisson distribution with weight <span class="math inline">\(1-p\)</span>.</p>
<p>The parameter <span class="math inline">\(p\)</span> can take values in <span class="math inline">\([0, 1]\)</span>, we transform the interval <span class="math inline">\([0, 1]\)</span> to the real line <span class="math inline">\((-\infty, \infty)\)</span> using the logit transform</p>
<p><span class="math display">\[ \text{logit}(p) = \log\left( \frac{p}{1-p} \right) = \beta. \]</span></p>
<p>Inverting this expression, we find</p>
<p><span class="math display">\[ p = \frac{\exp(\beta)}{ 1 + \exp(\beta) }.\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ZIP.negativeLoglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(beta)
{
  lambda &lt;-<span class="st"> </span><span class="kw">exp</span>(beta[<span class="dv">1</span>])
  p &lt;-<span class="st"> </span><span class="kw">exp</span>(beta[<span class="dv">2</span>])<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(beta[<span class="dv">2</span>]))
  
  density &lt;-<span class="st"> </span>(p <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>p) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>TLength <span class="op">*</span><span class="st"> </span>lambda))<span class="op">^</span>(Clm_Count <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">*</span><span class="st"> </span>((<span class="dv">1</span><span class="op">-</span>p) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>TLength <span class="op">*</span><span class="st"> </span>lambda) <span class="op">*</span><span class="st"> </span>(TLength <span class="op">*</span>lambda)<span class="op">^</span>Clm_Count <span class="op">/</span><span class="st"> </span><span class="kw">gamma</span>(Clm_Count<span class="op">+</span><span class="dv">1</span>))<span class="op">^</span>(Clm_Count <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>) 
  
  loglikelihood &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(density))
  
  <span class="kw">return</span>(<span class="op">-</span>loglikelihood)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">nlm</span>(ZIP.negativeLoglikelihood, <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),<span class="dt">hessian=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>Warning in nlm(ZIP.negativeLoglikelihood, c(0, 0), hessian = TRUE): NA/Inf
replaced by maximum positive value

Warning in nlm(ZIP.negativeLoglikelihood, c(0, 0), hessian = TRUE): NA/Inf
replaced by maximum positive value</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit</code></pre></div>
<pre><code>$minimum
[1] 50663

$estimate
[1] -1.3754 -0.4551

$gradient
[1] -0.02996  0.02012

$hessian
      [,1]  [,2]
[1,] 14607 -5623
[2,] -5623  2423

$code
[1] 1

$iterations
[1] 13</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ZIP.lambda &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">1</span>])
ZIP.p &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">2</span>])<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">2</span>]))
<span class="kw">c</span>(<span class="dt">lambda =</span> ZIP.lambda, <span class="dt">p =</span> ZIP.p)</code></pre></div>
<pre><code>lambda      p 
0.2527 0.3881 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ZIP.loglik &lt;-<span class="st"> </span><span class="op">-</span>fit<span class="op">$</span>minimum</code></pre></div>
<p>Many policyholders file zero claims, which is captured by increasing the probability of observing zero claims by <span class="math inline">\(38.8\%\)</span>.</p>
</div>
<div id="hurdle-poisson" class="section level4">
<h4><span class="header-section-number">4.3.3.2</span> Hurdle Poisson</h4>
<p>In the Hurdle Poisson we set the probability of observing zero claims to <span class="math inline">\(p\)</span>. Conditional on there being a claim the distribution follows a zero-truncated Poisson distribution. The probability of observing <span class="math inline">\(k\)</span> claims becomes</p>
<p><span class="math display">\[P(N = k) = 
\begin{cases} 
  p &amp; k = 0 \\
  (1-p) \cdot P(\tilde{N} = k \mid \tilde{N} &gt; 0) &amp; k &gt; 0
\end{cases},\]</span></p>
<p>where <span class="math inline">\(\tilde{N}\)</span> follows a Poisson distribution. The probability distribution of the zero-truncated Poisson distribution is given by</p>
<p><span class="math display">\[ P(\tilde{N} = k \mid \tilde{N} &gt; 0) = \frac{P(\tilde{N} = k)}{P(\tilde{N} &gt; 0)} = \frac{P(\tilde{N} = k)}{1- \exp(-\lambda)}.\]</span></p>
<p>We assume that the intensity of the zero-truncated Poisson distribution is proportional to the exposure, i.e. <span class="math inline">\(\lambda_i = d_i \cdot \lambda\)</span>. The probability of observing zero claims is <span class="math inline">\(p\)</span> and does not depend on the exposure <span class="math inline">\(d_i\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hurdle.negativeLoglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(beta)
{
  lambda &lt;-<span class="st"> </span><span class="kw">exp</span>(beta[<span class="dv">1</span>])
  p &lt;-<span class="st"> </span><span class="kw">exp</span>(beta[<span class="dv">2</span>])<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(beta[<span class="dv">2</span>]))
  
  density &lt;-<span class="st"> </span>(p)<span class="op">^</span>(Clm_Count <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="op">*</span><span class="st"> </span>((<span class="dv">1</span><span class="op">-</span>p) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>TLength <span class="op">*</span><span class="st"> </span>lambda) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>lambda <span class="op">*</span><span class="st"> </span>TLength)) <span class="op">*</span><span class="st"> </span>(TLength <span class="op">*</span>lambda)<span class="op">^</span>Clm_Count <span class="op">/</span><span class="st"> </span><span class="kw">gamma</span>(Clm_Count<span class="op">+</span><span class="dv">1</span>))<span class="op">^</span>(Clm_Count <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>) 
  
  loglikelihood &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(density))
  
  <span class="kw">return</span>(<span class="op">-</span>loglikelihood)
}</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">nlm</span>(Hurdle.negativeLoglikelihood, <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),<span class="dt">hessian=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>Warning in nlm(Hurdle.negativeLoglikelihood, c(0, 0), hessian = TRUE): NA/Inf
replaced by maximum positive value

Warning in nlm(Hurdle.negativeLoglikelihood, c(0, 0), hessian = TRUE): NA/Inf
replaced by maximum positive value</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit</code></pre></div>
<pre><code>$minimum
[1] 52955

$estimate
[1] -1.381  2.324

$gradient
[1] 4.741e-05 1.088e-02

$hessian
           [,1]       [,2]
[1,]  1.541e+03 -3.131e-04
[2,] -3.131e-04  1.299e+04

$code
[1] 1

$iterations
[1] 12</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hurdle.lambda &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">1</span>])
Hurdle.p &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">2</span>])<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">2</span>]))
<span class="kw">c</span>(<span class="dt">lambda =</span> Hurdle.lambda, <span class="dt">p =</span> Hurdle.p)</code></pre></div>
<pre><code>lambda      p 
0.2513 0.9108 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hurdle.loglik &lt;-<span class="st"> </span><span class="op">-</span>fit<span class="op">$</span>minimum</code></pre></div>
</div>
</div>
</div>
<div id="aic-1" class="section level2">
<h2><span class="header-section-number">4.4</span> AIC</h2>
<p>Suppose that we have a statistical model of some data. Let k be the number of estimated parameters in the model. Let <span class="math inline">\({\displaystyle {\hat {L}}}\)</span> be the maximum value of the likelihood function for the model. Then the AIC value of the model is the following</p>
<p><span class="math display">\[ \text{AIC} = 2 k - 2 \ln ( \hat{\mathcal{L}}) \]</span> Given a set of candidate models for the data, the preferred model is the one with the minimum AIC value. Thus, AIC rewards goodness of fit (as assessed by the likelihood function), but it also includes a penalty that is an increasing function of the number of estimated parameters. The penalty discourages overfitting, because increasing the number of parameters in the model almost always improves the goodness of the fit. For more information see <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">wikipedia</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">AIC &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">c</span>(<span class="st">&quot;AIC Poi&quot;</span> =<span class="st"> </span><span class="op">-</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>poisson.loglik <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">1</span>, 
               <span class="st">&quot;AIC NB&quot;</span> =<span class="st"> </span><span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>nb.loglik <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span>, 
               <span class="st">&quot;AIC ZIP&quot;</span> =<span class="st"> </span><span class="op">-</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>ZIP.loglik <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span>, 
               <span class="st">&quot;AIC Hurdle&quot;</span> =<span class="st"> </span><span class="op">-</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>Hurdle.loglik <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span>))
AIC</code></pre></div>
<pre><code>   AIC Poi     AIC NB    AIC ZIP AIC Hurdle 
    101670     101318     101330     105914 </code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">AIC[<span class="kw">which.min</span>(AIC)]</code></pre></div>
<pre><code>AIC NB 
101318 </code></pre>
<p>The lowest AIC value is achieved by the NB distribution, closely followed by the ZIP. The Hurdle distribution attains a remarkably higher AIC value which reflects the poor way in which the exposure is incorporated.</p>
</div>
<div id="replicating-data-sets" class="section level2">
<h2><span class="header-section-number">4.5</span> Replicating data sets</h2>
<p>We now show how to generate replicating data sets based on each of these models. We generate 5 random samples of the same size as the original data set and using the estimated parameters. We then plot the contingency tables to compare.</p>
<div id="poisson-1" class="section level3">
<h3><span class="header-section-number">4.5.1</span> Poisson</h3>
<p><code>rpois</code> allows us to generate from a Poisson distribution for any given positive lambda. We use the fitted lambdas, taking exposure into account. Notice that the length of argument lambda is <span class="math inline">\(n\)</span> whereas we sample <span class="math inline">\(5n\)</span> observations. <code>rpois</code> deals with this mismatch by recycling the lambdas <span class="math inline">\(5\)</span> times. The resulting output vector is then used to form a matrix with <span class="math inline">\(5\)</span> columns, filled by its columns (by default), such that each column contains a replicating data set.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="kw">length</span>(Clm_Count)
Repl.Poi &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rpois</span>(n<span class="op">*</span><span class="dv">5</span>, <span class="dt">lambda =</span> poisson.lambda<span class="op">*</span>TLength), <span class="kw">c</span>(n,<span class="dv">5</span>)) <span class="co"># or fitted(fm_pois) instead of Poi.lambda*TLength</span>

<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))
<span class="kw">plot</span>(<span class="kw">table</span>(Clm_Count), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>){
  <span class="kw">plot</span>(<span class="kw">table</span>(Repl.Poi[,i]), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">5</span>))
}</code></pre></div>
<p><img src="_main_files/figure-html/claimCounts_plot_simulated_poisson-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="nb" class="section level3">
<h3><span class="header-section-number">4.5.2</span> NB</h3>
<p><code>rnbinom</code> allows us to generate from a Negative Binomial distribution for a given mu and size. The rest is similar to the Poisson case.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Repl.NB &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnbinom</span>(n<span class="op">*</span><span class="dv">5</span>, <span class="dt">mu =</span> nb.mu <span class="op">*</span><span class="st"> </span>TLength, <span class="dt">size =</span> nb.a), <span class="kw">c</span>(n,<span class="dv">5</span>))

<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))
<span class="kw">plot</span>(<span class="kw">table</span>(Clm_Count),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>){
  <span class="kw">plot</span>(<span class="kw">table</span>(Repl.NB[,i]), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">5</span>))
}</code></pre></div>
<p><img src="_main_files/figure-html/claimCounts_plot_simulated_nb-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="zip" class="section level3">
<h3><span class="header-section-number">4.5.3</span> ZIP</h3>
<p>To generate data from the ZIP distribution we first simulate Poisson distributed data. Afterwards, each observation is set to zero with probability <span class="math inline">\(p\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&#39;VGAM&#39;)</span>
<span class="co"># install.packages(&#39;gamlss.dist&#39;)</span>

Repl.ZIP &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rpois</span>(n <span class="op">*</span><span class="st"> </span><span class="dv">5</span>, <span class="dt">lambda =</span> ZIP.lambda <span class="op">*</span><span class="st"> </span>TLength) <span class="op">*</span><span class="st"> </span>(<span class="kw">runif</span>(n <span class="op">*</span><span class="st"> </span><span class="dv">5</span>) <span class="op">&gt;</span><span class="st"> </span>ZIP.p), <span class="kw">c</span>(n, <span class="dv">5</span>))

<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))
<span class="kw">plot</span>(<span class="kw">table</span>(Clm_Count),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>){
  <span class="kw">plot</span>(<span class="kw">table</span>(Repl.ZIP[,i]), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">5</span>))
}</code></pre></div>
<p><img src="_main_files/figure-html/claimCounts_plot_simulated_zip-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="hurdle-poisson-1" class="section level3">
<h3><span class="header-section-number">4.5.4</span> Hurdle Poisson</h3>
<p>We first simulate data from a Poisson distribution, where we discard all observations with zero claims. As such, this is a simulation from a zero-truncated distribution. Afterwards, each observation is set to zero with probability <span class="math inline">\(p\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">initial.sim &lt;-<span class="st"> </span><span class="kw">rpois</span>(n <span class="op">*</span><span class="st"> </span><span class="dv">50</span>, <span class="dt">lambda =</span> Hurdle.lambda <span class="op">*</span><span class="st"> </span>TLength)
initial.sim &lt;-<span class="st"> </span>initial.sim[initial.sim <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>]

Repl.Hurdle &lt;-<span class="st"> </span><span class="kw">matrix</span>(initial.sim[<span class="dv">1</span><span class="op">:</span>(n<span class="op">*</span><span class="dv">5</span>)] <span class="op">*</span><span class="st"> </span>(<span class="kw">runif</span>(n <span class="op">*</span><span class="st"> </span><span class="dv">5</span>) <span class="op">&gt;</span><span class="st"> </span>Hurdle.p), <span class="kw">c</span>(n, <span class="dv">5</span>))

<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))
<span class="kw">plot</span>(<span class="kw">table</span>(Clm_Count),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>){
  <span class="kw">plot</span>(<span class="kw">table</span>(Repl.Hurdle[,i]), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">5</span>))
}</code></pre></div>
<p><img src="_main_files/figure-html/claimCounts_plot_simulated_hurdle-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="mean-and-variance-of-the-estimated-zip-nb-hurdle-poisson" class="section level2">
<h2><span class="header-section-number">4.6</span> Mean and variance of the estimated ZIP, NB, Hurdle Poisson</h2>
<p>We calculate the mean and variance of the estimated Poisson, NB, ZIP, and Hurdle Poisson (with exposure equal to one) and compare these with the empirical mean and variance. We expect that a model fitting the data well will have a similar mean and variance. Try to derive the stated expressions for the mean and variance yourself as an exercise.</p>
<div id="poisson-2" class="section level3">
<h3><span class="header-section-number">4.6.1</span> Poisson</h3>
<p>For the Poisson distribution <span class="math inline">\(N \sim Poi(\lambda)\)</span>, the mean and the variance are both equal to <span class="math inline">\(\lambda\)</span>. This is called equidispersion.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">poisson.lambda</code></pre></div>
<pre><code>[1] 0.1546</code></pre>
</div>
<div id="nb-1" class="section level3">
<h3><span class="header-section-number">4.6.2</span> NB</h3>
<p>For the negative binomial distribution <span class="math inline">\(N \sim NB(a, \lambda)\)</span>, the mean equals <span class="math display">\[ E(N) = \lambda \]</span> and the variance <span class="math display">\[ \mathrm{var}(N) = \lambda + \lambda^2 / a  \]</span> exceeds the mean (overdispersion).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NB.mean &lt;-<span class="st"> </span>nb.mu
NB.mean</code></pre></div>
<pre><code>[1] 0.1546</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">NB.var &lt;-<span class="st"> </span>nb.mu <span class="op">+</span><span class="st"> </span>nb.mu<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>nb.a
NB.var</code></pre></div>
<pre><code>[1] 0.171</code></pre>
</div>
<div id="zip-1" class="section level3">
<h3><span class="header-section-number">4.6.3</span> ZIP</h3>
<p>For the zero inflated Poisson distribution <span class="math inline">\(N \sim ZIP(p, \lambda)\)</span>, the mean equals <span class="math display">\[ E(N) = (1-p)\lambda \]</span> and the variance <span class="math display">\[ \mathrm{var}(N) = (1-p)(\lambda^2 + \lambda ) - (1-p)^2 \lambda ^2 = E(N) + \frac{p}{1-p} E(N)^2. \]</span></p>
<p>From the last expression we notice that the ZIP is overdispersed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ZIP.mean &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>ZIP.p)<span class="op">*</span>ZIP.lambda
ZIP.mean</code></pre></div>
<pre><code>[1] 0.1546</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ZIP.var &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>ZIP.p)<span class="op">*</span>(ZIP.lambda<span class="op">^</span><span class="dv">2</span><span class="op">+</span>ZIP.lambda) <span class="op">-</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>ZIP.p)<span class="op">^</span><span class="dv">2</span><span class="op">*</span>ZIP.lambda<span class="op">^</span><span class="dv">2</span>
ZIP.var &lt;-<span class="st"> </span>ZIP.mean <span class="op">+</span><span class="st"> </span>ZIP.p<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>ZIP.p)<span class="op">*</span>ZIP.mean<span class="op">^</span><span class="dv">2</span>
ZIP.var</code></pre></div>
<pre><code>[1] 0.1698</code></pre>
</div>
<div id="hurdle-poisson-2" class="section level3">
<h3><span class="header-section-number">4.6.4</span> Hurdle Poisson</h3>
<p>For the hurdle Poisson distribution <span class="math inline">\(N \sim \mathrm{Hurdle}(p, \lambda)\)</span>, the mean equals <span class="math display">\[ E(N) = \frac{1-p}{1-e^{-\lambda}}\lambda \]</span> and the variance <span class="math display">\[ \mathrm{var}(N) = \frac{1-p}{1-e^{-\lambda}} (\lambda^2 + \lambda) - E(N)^2 = E(N) + \frac{p-e^{-\lambda}}{1-p} E(N)^2. \]</span> From the last expression we notice that the Hurdle Poisson is overdispersed if <span class="math inline">\(p &gt; e^{-\lambda}\)</span>, or, if the probability mass at zero is larger than it would be under a regular Poisson setting.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># note that Hurdle.p = 1-fhurdle.p = q = P(N=0)</span>

Hurdle.mean &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>Hurdle.p)<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>Hurdle.lambda))<span class="op">*</span>Hurdle.lambda
Hurdle.mean</code></pre></div>
<pre><code>[1] 0.1009</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Hurdle.var &lt;-<span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>Hurdle.p)<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>Hurdle.lambda))<span class="op">*</span>(Hurdle.lambda<span class="op">^</span><span class="dv">2</span><span class="op">+</span>Hurdle.lambda) <span class="op">-</span><span class="st"> </span>Hurdle.mean<span class="op">^</span><span class="dv">2</span>
Hurdle.var &lt;-<span class="st"> </span>Hurdle.mean <span class="op">+</span><span class="st"> </span>(Hurdle.p<span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>Hurdle.lambda))<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span>Hurdle.p)<span class="op">*</span>Hurdle.mean<span class="op">^</span><span class="dv">2</span>
Hurdle.var</code></pre></div>
<pre><code>[1] 0.116</code></pre>
</div>
<div id="comparison-with-empirical-mean-and-variance" class="section level3">
<h3><span class="header-section-number">4.6.5</span> Comparison with empirical mean and variance</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">means &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;mean Obs&quot;</span> =<span class="st"> </span>mu, <span class="st">&quot;mean Poisson&quot;</span> =<span class="st"> </span>poisson.lambda, <span class="st">&quot;mean NB&quot;</span> =<span class="st"> </span>NB.mean, <span class="st">&quot;mean ZIP&quot;</span> =<span class="st"> </span>ZIP.mean, <span class="st">&quot;mean Hurdle&quot;</span> =<span class="st"> </span>Hurdle.mean)
means</code></pre></div>
<pre><code>    mean Obs mean Poisson      mean NB     mean ZIP  mean Hurdle 
      0.1546       0.1546       0.1546       0.1546       0.1009 </code></pre>
<p>All distributions expect the hurdle distribution closely approximate the mean of the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">variances &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;variance Obs&quot;</span> =<span class="st"> </span>var, <span class="st">&quot;variance Poisson&quot;</span> =<span class="st"> </span>poisson.lambda, <span class="st">&quot;variance NB&quot;</span> =<span class="st"> </span>NB.var, <span class="st">&quot;variance ZIP&quot;</span> =<span class="st"> </span>ZIP.var, <span class="st">&quot;variance Hurdle&quot;</span>=Hurdle.var)
variances </code></pre></div>
<pre><code>    variance Obs variance Poisson      variance NB     variance ZIP 
          0.1675           0.1546           0.1710           0.1698 
 variance Hurdle 
          0.1160 </code></pre>
<p>The hurlde distribution also severly underestimates the variance in the data. Since the NB distribution and the ZIP have two parameters they are more flexibility and can capture both the mean and variance well.</p>
</div>
</div>
<div id="conclusion" class="section level2">
<h2><span class="header-section-number">4.7</span> Conclusion</h2>
<p>We have investigated the number of claims per policyholder when taking exposure into account. All of our analyses show that the NB distribution is a good fit. The NB has the lowest AIC, the mean and variance of the data are well captured and relation of the (a, b, 0) class <span class="math display">\[ \frac{k \cdot p_k}{p_{k-1}} = a \cdot k + b, \]</span> seems to be satisfied for a positive value of <span class="math inline">\(a\)</span>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simple-parametric-distributions-for-frequency-and-severity-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="simulation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
